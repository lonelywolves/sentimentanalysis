- Every once in a while,
I get my hands on something
so special, so unique
that not only does nobody have one,
almost no one even knows that it exists.
And today is one of those days.
Thanks to rare tech collector YuuKi-AnS,
I'm gonna go with YuuKi.
On our forum, I have this,
a hopefully working prototype
of the long lost Vegas 16,
a graphics card from AMD,
that never saw the light of day.
Was it for the best?
Does it suck?
Wow we're gonna find out,
our ladies and gentlemen,
after this message from our sponsor,
World of Warships.
World of Warships is the online
free to play strategy game
that features millions of players,
battling to upgrade
their armory of ships, weapons and armor.
Tune in at the end of the video
or click the link below,
to learn more.
(upbeat music)
This is crazy.
Sometimes you'll see a prototype card
that you look closely at it and you go,
that was basically a qualifying sample,
this,
(laughs)
not so much,
this thing is Dev board AF.
So all these leads up here
are on the top edge of the board,
so you'd be able to plug like
some kind of custom
proprietary harness onto them.
These are all soldered on.
So they would use that
usually for things like
monitoring the thermals
or the power consumption of the board,
while they are developing
the drivers for it.
On the other side,
we've got just the right mix
of what I would call professional Cluj.
This is a proper-ish cooling solution,
you can see there's
radian branding on the fan
and this heatsink here,
looks to be actually
custom-made for this board.
But then in terms of
how they're keeping it cool,
Well, it's just like
yeah, there's this random fan
kind of bolted on to it.
And we've got a theory
as to why it's set up like this.
Now with a desktop card,
you would create a reference cooler for it
at the same time
that you're creating the reference board.
But check this out.
The bottom edge of the card
only has enough pins
for a PCI Express eight x interface.
So it's got a 16 x connector on it,
because they would have
been validating this GPU,
in a desktop motherboard,
they would have needed
to just chunk it in there,
but this would have been a laptop product
at the end of the day.
And until very recently,
pretty much all dedicated GPUs and laptops
ran eight x interfaces.
Another oddity is this,
check this out.
It's got all DisplayPort ports, no HDMI.
So that would mean that this board
if it was ever destined for release,
would have probably been like
a workstation board or
something like that.
Like there's no way
this would have ended up
in a gaming GPU,
8 pin power connector, oof!
unlike a low tier Vega 16 I mean,
I guess you would just put it on
and then we've seen this before
actually finished reference designs
that just have the contact
pads for a connector,
but it's just not on there.
So maybe it's just in case,
hoping for the best.
(upbeat music)
(claps)
Roll it up, ladies and gentlemen.
Oh wow, that's gross.
Okay, so this seems to
be running at 24 hertz.
(upbeat music)
I don't even think that's 31 hertz.
That is 24 times more cinematic
than your favorite films.
The only option in the basic
display adapter properties
here is 64 hertz.
wait, no that can't be one hertz.
That's not even right.
What's even going on right now.
4k, 24 hertz.
I believe that,
I don't believe one or 64
looking at this that is entirely(mumbles),
So we've just got
the Microsoft BASIC
Display Adapter Driver.
Anthony, did you have
any AMD drivers on this before?
Like did this have
an AMD GPU in it before?
Would it have had a chance to grab it?
- [Anthony] No.
- okay,
- [Anthony] no.
Okay, so that makes sense.
Let's go ahead
and fire up GPU z
and see what this thing picks up as.
Normally, even if we're talking
about graphics cards
that have had their
firmware tampered with by,
wish scammers or pre-production CPUs,
it'll normally be able
to grab things like how much cash
is on this CPU or whatever else,
like, half of these fields,
are not populated.
Direct X Support unknown,
Shaders unknown, ROP's unknown.
It just has no idea what's going on.
So it knows default clock
but not GPU clock,
it can't read it.
It knows it has HBM2 memory
but it thinks it has zero megabytes.
Even many of the fields
that are populated are clearly wrong.
It says it's running PCIe x 16 3.0,
but we know it doesn't even
have enough pins for that.
These are the latest adrenalin drivers
from AMD's website,
if there's anything
that would know what this card is,
would obviously be
AMD's own drivers right?
I doubt this is going to work.
Normally they have to manually add
the IDs for every card
that the driver works with.
So if there was some way
for us to know what that was
and add it in,
I don't know maybe but probably not.
Ltt.store.com suckers,
(bottle crackling)
Oops! Something went wrong,
now that's interesting though,
that error message,
it did detect AMD graphics hardware,
but just not supported
AMD graphics hardware.
We might not be defeated yet.
This wouldn't be an Anthony video,
if there wasn't some reason
to have Linux come in and save the day.
Where's my Linux boot drive?
I am legitimately excited about this.
I had no idea that
any of that random grab
bag of stuff YuuKi stuff,
was gonna actually fire up.
And nothing, we are not doing yet though,
Vega owners, even the ones
who bought finished cards
have had some issues in Linux,
and there's kind of a
list of tips and tricks
that we can try starting,
with unplugging our display cable
from the graphics card
and plugging it into our onboard GPU.
Which means we need an HDMI connection.
♪ HDMI to the rescue ♪
It fired our video up.
look at that, oh interesting.
That VGA compatible
controller, MBTI Vega 12.
Ha, like Vega 12,
that's a finished notebook GPU, isn't it?
- [Anthony] I believe
it's built into the GPUs,
the high end GPUs,
but I'm not sure.
- At this stage, we could attempt
to use our Vega 16,
but it's very unlikely to work
without a couple of
kernel parameter changes.
Amdgpu.vm_update_mode equals three,
and it's gonna tell the driver to use
the CPU to update video
memory when needed,
we also need to turn dynamic
power management off,
we need to disable some
more power management features,
we need to make sure
the system doesn't try
and continue running the card,
if it runs into a problem,
we need to provide more
information for troubleshooting.
It's not strictly speaking needed,
but it may help us diagnose
any further issues.
And we need to disable GPU recovery,
in the case of a crash.
Now this isn't gonna let the card,
just boot up like it
was able to in Windows,
but we should be able
to render our games on the card
and then pass through
the work that's been done
to the integrated GPU,
kind of like we did,
when we got that mining card running
in Windows in games.
Anthony prepared all that stuff
in Manjaro, Linux Vega 16.
It's our own special branch of Linux,
just in case you've got
one of these cards that you need to run.
Glx gears is a simple render test
and we're gonna run the
Vegas 16 version of it,
to make sure that the rendering is done,
on the graphics card,
rather than the onboard,
like I described before,
and that is some really ugly artifacting.
Like, what does that look like?
That looks like a memory problem to you?
- [Anthony] Yeah, it
kind of looks like it.
- But it's working.
- [Anthony] Yeah.
- That's wow, okay,
the only way to know
if it's working for sure
is to know that it's like heating up.
Do we know for sure
that that's rendering on this one.
- [Anthony] So here we have,
all of the information saying
the GLRENDERER is
currently the AMD Vega 12.
If I ran it without that parameter,
it would just run on
the standard integrated graphics.
- Really isn't running very warm,
apparently, this is running
with V sync on though
so that could be part of the reason
it's just not working that hard.
let's fire up a game, shall we?
Roll Cisco?
Alright, let's do it.
We're playing some Vegas 16 CS go.
Someone at home,
it's like from that labs.
You'd be like, oh, what
happened to that thing?
Given that weird artifacting
we saw in the render test.
This is way better
than I would have expected.
Oh, it's definitely heating up now.
We're looking At 5060 FPS running
at 1080 all high anti aliasing off.
I mean, it's playable,
like well playable.
It's not great,
but it's playable.
(soft music)
I'm real sorry source engine,
a gamer job.
To put those performance
numbers in context,
we went ahead and fired up
the same game running
at the same settings
on the onboard graphics system.
We're looking at about 30
to 35 frames per second.
So yeah, given that
that's a comparison to onboard graphics,
the Vegas 16 is not exactly
a high performance part,
but it's working.
Let's go back to our
non-modified kernel Linux
and try one more thing.
This is a little tool called CoreCtrl.
We can pull up the system tab
and have a look at what we got in here.
Yep, that doesn't really tell
oh, hey no we've got a
new piece of information.
Apparently it has four
gigs of RAM, fascinating.
I mean, it might be right.
It also might not
'cause it thinks it's
a Vega 12 and all that,
but okay, anyway more interestingly,
we can go into our profile here,
fire up GPU one.
Okay, and check this out.
We can take this slider
and move it all the way to the right.
Pretty cool, this may
give us more performance.
I mean, going from 300
megahertz to 1300 megahertz,
assuming those numbers mean anything.
Should be a pretty
significant performance bond.
Dang, it's real working now.
This is crazy.
So what is this thing?
it's got 16 compute units,
which makes it more
like into a mobile part.
But it's got like
1300 megahertz core clock
speeds, HBM to memory,
what is it?
Maybe it was gonna be like
a mid range fire GL card.
But then if that four
gigs of RAM is right,
that wouldn't be enough for work,
so it crashed.
In fairness, it wasn't done, right?
Now there are a few more things
that we could try.
What we suspect is that
by dragging the sliders
all the way to the right,
we were actually putting the card
in kind of an overclocked state
like its maximum possible turbo.
And so the way that AMD
would probably be working on this card
is they would be trying
all these different power profiles,
monitoring voltages,
monitoring temperatures,
monitoring power draw,
using all these leads on the back end,
you would eventually end up
with a driver that's tuned
so that it'll burst up like that
but won't necessarily try to stay there.
So we're not gonna try
and do the entire AMD
hardware engineering and
software driver teams jobs
with this one engineering board.
So that's pretty much
the end of our experiment.
And I'm sure you guys would love,
to see us pull the cooler off,
take off the thermal paste,
like really dig into this thing
and look at what's there.
But remember guys,
we didn't pay for this,
we do need to return it,
still as functional as it is,
so I'm just gonna leave that alone
and just thank YuuKi,
for lending us this card.
And also thank our sponsor
for sponsoring this video.
This video is brought to you
by World of Warships,
the strategy action game
that someone referred to as
the thinking man's action game,
you can battle it out
with over 7 million players worldwide
and each in game ship is based on 3D scans
of real life ships.
There are over 200 ships to unlock like
the historic USS Missouri
and USS Arizona
and there's four classes of ships,
a bunch of upgrades, weather effects,
and strategically designed environments
so the action never ends
and every match is different.
Submarines are coming soon,
which will offer
a completely new style of gameplay.
New players can use code
READY4BATTLE2020 to receive 252 balloons,
a million credits the USS Charlson
three days premium time,
one port slot and more.
So check it out at the link
in the video description.
Thanks for watching guys
if you're looking for
something else to watch,
why not check out our
sort of similar-ish video,
where we got an old mining GPU
so one with no display outputs whatsoever
and used it to run games.
Baby faced me
is gonna see you there.
